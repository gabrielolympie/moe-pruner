{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f9c639-2297-4c3a-92e7-7eddb205b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901972b0-fc72-4e80-8e4b-28bfbe08a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from awq.modules.linear.gemm import WQLinear_GEMM\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from accelerate import init_empty_weights\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "from utils.ademamix import AdEMAMix\n",
    "from utils.config_utils import GenerationParams, PathConfig, DistillationParams\n",
    "from utils.experts_merge_utils import dequantize_GEMM\n",
    "from utils.torch_utils import (\n",
    "    destruct_module_optimized,\n",
    "    memory_cleanup,\n",
    "    rsetattr,\n",
    "    load_weights,\n",
    "    rhasattr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551cbb8e-19a6-4140-b77f-09ff78e3ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model_name = \"../deepseek_coder_v2_lite_instruct_awq\"\n",
    "n_epochs = 0\n",
    "start_layer = 0\n",
    "end_layer = 0\n",
    "target_routed_expert = 4\n",
    "target_active_expert = 4\n",
    "dora_rank = 16\n",
    "calibrate_merge= True\n",
    "pruning_method= \"multiplex\"\n",
    "\n",
    "path_config = PathConfig(\n",
    "    model_name = model_name,\n",
    "    intermediate_states = \"../data/intermediate_states\",\n",
    "    expert_states = \"../data/expert_states\",\n",
    "    expert_activations = \"../data/expert_activations\",\n",
    "    distillation_logs = \"distillation_logs\",\n",
    "    moe_states=\"../moe_states\"\n",
    ")\n",
    "\n",
    "distillation_config = DistillationParams(\n",
    "    n_epochs= n_epochs,\n",
    "    target_routed_expert = target_routed_expert,\n",
    "    target_active_expert = target_active_expert,\n",
    "    eval_batches=16,\n",
    "    gradient_accumulation_steps= 4,\n",
    "    learning_rate= 3e-4,\n",
    "    end_factor= 0.2,\n",
    "    calibrate_merge=calibrate_merge,\n",
    "    skip_first_tokens=0, ## useful to avoid tuning on early tokens that have less informations\n",
    "    pruning_method=pruning_method, # topk , act_cl, state_cl\n",
    "    dora_rank=dora_rank,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d259692-4b3d-4819-ac87-32bab2453362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded an AWQ model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd4abb3c2ed4dbeb271ce1bde54c4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Loading model')\n",
    "\n",
    "from patched_modules.configuration_deepseek_fused_v2 import DeepseekV2Config\n",
    "from patched_modules.modeling_deepseek_fused_v2 import MultiplexedMOE\n",
    "\n",
    "\n",
    "with open(f\"{model_name}/model.safetensors.index.json\", \"r\") as f:\n",
    "    weight_map = json.load(f)[\"weight_map\"]\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "\n",
    "for name, parameter in model.named_parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "config=AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "config.n_multiplexed_routed_experts=distillation_config.target_routed_expert\n",
    "\n",
    "\n",
    "model.train()\n",
    "destruct_module_optimized(model)\n",
    "memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf96983e-3d6c-40b8-9f02-66e8f79d5579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(model.model.layers)):\n",
    "    if rhasattr(model, f\"model.layers.{i}.mlp.experts\"):\n",
    "        rsetattr(model, f\"model.layers.{i}.mlp.experts\", torch.nn.Module()) ## ensuring destruction of experts to avoid oom\n",
    "\n",
    "model=model.to_empty(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342dd298-e04a-4e5d-b759-2f1ff4189bc4",
   "metadata": {},
   "source": [
    "## Load non expert weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7263098-c527-47e6-bc2d-39fa0a03bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4622f4fa444f470399de4126cdc4602a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_modules=[]\n",
    "for elt in weight_map:\n",
    "    if not('.experts.' in elt):\n",
    "        if not('gate.weight' in elt):\n",
    "            target_modules.append(elt)\n",
    "\n",
    "model=load_weights(model, model_name, weight_map, target_modules, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093aa3a8-6f7f-4896-848d-f543f3b50a46",
   "metadata": {},
   "source": [
    "## Reinitialize experts with new number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6642ade7-2127-4481-b703-ee91df6a8df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca7c4ed0b9340daa24e8394cb6bd98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../moe_states/distillat_multiplex_4/layer_4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m shared\u001b[38;5;241m=\u001b[39mdeepcopy(layer\u001b[38;5;241m.\u001b[39mmlp\u001b[38;5;241m.\u001b[39mshared_experts)\n\u001b[1;32m      5\u001b[0m export_path\u001b[38;5;241m=\u001b[39mpath_config\u001b[38;5;241m.\u001b[39mmoe_states\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/distillat_multiplex_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistillation_config\u001b[38;5;241m.\u001b[39mtarget_routed_expert\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/layer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m new_state_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../moe_states/distillat_multiplex_4/layer_4'"
     ]
    }
   ],
   "source": [
    "for layer_idx, layer in enumerate(tqdm(model.model.layers)):\n",
    "    if rhasattr(layer.mlp, \"experts\"):\n",
    "        shared=deepcopy(layer.mlp.shared_experts)\n",
    "        \n",
    "        export_path=path_config.moe_states+f\"/distillat_multiplex_{distillation_config.target_routed_expert}/layer_{layer_idx}\"\n",
    "        state_dict = torch.load(export_path)\n",
    "        \n",
    "        new_state_dict = {}\n",
    "        for key in state_dict.keys():\n",
    "            new_key = key.replace('multiplexed_experts', 'experts')\n",
    "            new_state_dict[new_key] = state_dict[key]\n",
    "        \n",
    "        layer.mlp=MultiplexedMOE(config)\n",
    "        layer.mlp.shared_experts=deepcopy(shared)\n",
    "        layer.mlp.load_state_dict(new_state_dict)\n",
    "        layer.mlp.shared_experts=shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b86a5c-b18a-4ed3-b72c-dcf48c9c02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d69f0-0e41-4662-b6c3-24ff997e7b30",
   "metadata": {},
   "source": [
    "## Dequant every WQLinear_GEMM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e8b40-f16d-445e-8415-5948fffbf3fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, params = dequantize_GEMM(model, dtype=torch.bfloat16)\n",
    "model.to('cuda:0', dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e00f6c-451f-4685-a973-48ce04ec6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('updating config')\n",
    "\n",
    "model.config=config\n",
    "\n",
    "print('Saving')\n",
    "unhealed_name=model_name+f\"_fused_{distillation_config.target_routed_expert}_unhealed\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "tokenizer.save_pretrained(unhealed_name)\n",
    "model.save_pretrained(unhealed_name)\n",
    "\n",
    "shutil.copy(os.path.join('../patched_modules/', 'modeling_deepseek_fused_v2.py'), os.path.join(unhealed_name, 'modeling_deepseek.py'))\n",
    "shutil.copy(os.path.join('../patched_modules/', 'configuration_deepseek_fused_v2.py'), os.path.join(unhealed_name, 'configuration_deepseek.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04847743-9536-4afd-995b-fb445ed466b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42619b4-d945-4346-80aa-48041e2ec8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
