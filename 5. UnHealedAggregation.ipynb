{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ea0ed-f3df-4aa9-9355-7622e65090cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from configs import DistillationParams, PathConfig\n",
    "import torch\n",
    "from Distiller import (\n",
    "    IntermediateStateDataset,\n",
    "    prepare_distilled_moe,\n",
    "    MOEDistillerLightningModule,\n",
    "    OptimizerModeCallback,\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.multiprocessing as mp\n",
    "import argparse\n",
    "\n",
    "from torch_utils import memory_cleanup, destruct_module_optimized, count_parameters\n",
    "from model_utils import (\n",
    "    rsetattr,\n",
    "    rgetattr,\n",
    "    load_model_config,\n",
    "    load_weight,\n",
    "    map_device,\n",
    "    assign_device,\n",
    "    get_dataset,\n",
    "    get_device_map,\n",
    ")\n",
    "from accelerate import init_empty_weights\n",
    "from modeling_deepseek import (\n",
    "    DeepseekV3DecoderLayer,\n",
    "    DeepseekV3MoE,\n",
    "    DeepseekV3ForCausalLM,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from fp8_linear import FP8Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec49a97-d39c-4f8e-a704-eb62b3c02582",
   "metadata": {},
   "source": [
    "## Instantiate empty model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0843664-e661-471a-a9c2-69d1a3e47fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config = PathConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08388ad5-eb8e-49a7-b919-d1ae96c0f1dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights_location = \"deepseek_v3\"\n",
    "\n",
    "weight_map, config = load_model_config(weights_location)\n",
    "# Create empty model\n",
    "with init_empty_weights():\n",
    "    model = DeepseekV3ForCausalLM(config)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "destruct_module_optimized(model)\n",
    "memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221a9aa-b7ce-43d0-9e4a-f574a181199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "device_map = []\n",
    "\n",
    "for elt in weight_map:\n",
    "    if not (\"experts\" in elt):\n",
    "        if not (\".gate.\" in elt):\n",
    "            if not (\".61.\" in elt):\n",
    "                device_map.append(elt)\n",
    "\n",
    "for i, weight_name in enumerate(tqdm(device_map)):\n",
    "    rsetattr(\n",
    "        model,\n",
    "        weight_name,\n",
    "        load_weight(weights_location, weight_name, weight_map, device),\n",
    "    )\n",
    "    if i % 100 == 0:\n",
    "        memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a76f4e-1198-4af5-bc40-9ca95001da89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_routed_experts = 8\n",
    "n_active_experts = 4\n",
    "model_name = f\"{weights_location}_{n_routed_experts}a{n_active_experts}\"\n",
    "\n",
    "model.config.n_routed_experts = n_routed_experts\n",
    "model.config.num_experts_per_tok = n_active_experts\n",
    "\n",
    "for layer_idx in tqdm(range(3, 61)):\n",
    "    with init_empty_weights():\n",
    "        model.model.layers[layer_idx].mlp = DeepseekV3MoE(model.config)\n",
    "\n",
    "    model.model.layers[layer_idx].mlp.load_state_dict(\n",
    "        torch.load(\n",
    "            os.path.join(\n",
    "                path_config.base_dir,\n",
    "                f\"{weights_location}_{n_routed_experts}@{n_active_experts}\",\n",
    "                f\"layer_{layer_idx}.pt\",\n",
    "            )\n",
    "        ),\n",
    "        assign=True,\n",
    "    )\n",
    "    model.model.layers[layer_idx].mlp = model.model.layers[layer_idx].mlp.to(device)\n",
    "    print(f\"Layer {layer_idx} pruning\")\n",
    "    count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd542bd-963d-4e5d-9324-de3e57076a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in tqdm(model.named_modules()):\n",
    "    if isinstance(module, FP8Linear):\n",
    "        rsetattr(model, name, module.to_linear(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7f901-12c1-4ed6-8f54-654b9ead1933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = f\"{weights_location}_{n_routed_experts}a{n_active_experts}\"\n",
    "model.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d19bbb-9ca2-464e-9f65-a4af62fe5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy(\"configuration_deepseek.py\", f\"{model_path}/configuration_deepseek.py\")\n",
    "\n",
    "with open(\"modeling_deepseek.py\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = data.replace(\"from fp8_linear import FP8Linear\", \"\")\n",
    "data = data.replace(\"FP8Linear\", \"nn.Linear\")\n",
    "\n",
    "with open(f\"{model_name}/modeling_deepseek.py\", \"w\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b56d2-7a69-4c3c-8f94-0c96c7ada87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
