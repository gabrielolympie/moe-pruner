{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea040984-dd1a-434e-a9cf-c71034a2ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from configs import DistillationParams, PathConfig\n",
    "import torch\n",
    "from Distiller import IntermediateStateDataset, prepare_distilled_moe, MOEDistillerLightningModule\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping  \n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.multiprocessing as mp\n",
    "from ademamix import AdEMAMix\n",
    "import argparse\n",
    "\n",
    "from torch_utils import memory_cleanup, destruct_module_optimized\n",
    "from model_utils import rsetattr, rgetattr, load_model_config, load_weight, map_device, assign_device, get_dataset, get_device_map\n",
    "from accelerate import init_empty_weights\n",
    "from modeling_deepseek import DeepseekV3DecoderLayer, DeepseekV3MoE, DeepseekV3ForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e90676-1573-4ef5-80d4-1d72dbc3c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Use GPUs 0 and 2\n",
    "# torch.cuda.set_device(\"cuda:1\")\n",
    "torch.backends.cuda.max_split_size_mb = 512\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "path_config = PathConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff35bf-a63c-4bda-b7ae-967e51e9496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_routed_experts = 8\n",
    "n_active_experts = 2\n",
    "learning_rate = 8e-4  # 0.0008\n",
    "end_factor = 0.1\n",
    "lora_rank = 16\n",
    "lora_alpha = 16\n",
    "device = \"cuda:0\"\n",
    "min_layer = 3\n",
    "max_layer = 61\n",
    "weights_location = 'deepseek_v3/'\n",
    "\n",
    "layer_idx=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b2031-ff8e-4be6-87c5-2612f7bd6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=int(device.split(':')[1])\n",
    "print('****************************************')\n",
    "\n",
    "params = DistillationParams(\n",
    "    n_epochs=10,\n",
    "    n_batch=256,\n",
    "    n_train_batch=232,\n",
    "    batch_size=8,\n",
    "    max_length=512,\n",
    "    gradient_accumulation_steps=1,\n",
    "    calibration_batches=16,\n",
    "    learning_rate=learning_rate,\n",
    "    end_factor=end_factor,\n",
    "    temperature=1.0,\n",
    "    lora_type=\"dora\",\n",
    "    lora_rank=lora_rank,\n",
    "    lora_alpha=lora_alpha,\n",
    "    max_workers=8,\n",
    "    fp8_format=\"e4m3\",\n",
    "    distiller_device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490e4a3-c088-4627-b29f-12a3dae14eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model Config and Tokenizer\n",
    "weight_map, config = load_model_config(weights_location)\n",
    "# Create empty model\n",
    "with init_empty_weights():\n",
    "    model = DeepseekV3ForCausalLM(config)\n",
    "\n",
    "destruct_module_optimized(model)\n",
    "memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd75f60-585d-41f9-800f-bdc868531000",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "full_dataset = IntermediateStateDataset(path_config, layer_idx, 0, params.n_batch)\n",
    "\n",
    "train_size = params.n_train_batch\n",
    "val_size = params.n_batch - params.n_train_batch\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "print(\"Dataset loaded and split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ae028-025c-43a7-98b4-c891bdb4e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8a081-00b4-4410-a5f1-3b3ef226ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.device(device):\n",
    "    device_map = get_device_map(layer_idx, weight_map, device)\n",
    "    model.model.layers[layer_idx] = model.model.layers[layer_idx].to_empty(device=device)\n",
    "    \n",
    "    for i, weight_name in enumerate(tqdm(device_map)):\n",
    "        rsetattr(model, weight_name, load_weight(weights_location, weight_name, weight_map, device))\n",
    "        if i%100 ==0:\n",
    "            memory_cleanup()\n",
    "    \n",
    "    model.model.layers[layer_idx] = model.model.layers[layer_idx].to(device)\n",
    "    memory_cleanup()\n",
    "    \n",
    "    with open(f\"{path_config.expert_activation_dir}/layer_{layer_idx}.pickle\", \"rb\") as f:\n",
    "        act = pickle.load(f)\n",
    "    \n",
    "    v,c = np.unique(act, return_counts=True)\n",
    "    selected_experts = np.flip(np.argsort(c))\n",
    "    \n",
    "    \n",
    "    pl_model = MOEDistillerLightningModule(\n",
    "        weight_map,\n",
    "        path_config,\n",
    "        params,\n",
    "        layer_idx=layer_idx,\n",
    "        n_routed_experts=n_routed_experts,\n",
    "        n_active_experts=n_active_experts,\n",
    "        weights_location=weights_location,\n",
    "    )\n",
    "    \n",
    "    pl_model.distillat=prepare_distilled_moe(\n",
    "        model.model.layers[layer_idx].mlp,\n",
    "        selected_experts,\n",
    "        n_routed_experts,\n",
    "        n_active_experts,\n",
    "        params,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    destruct_module_optimized(model)\n",
    "    memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c0f86-dc2c-42d6-9448-b1632159db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    path_config.log_dir,\n",
    "    name=f\"lightning_logs_layer_{layer_idx}_{n_routed_experts}a{n_active_experts}\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=path_config.checkpoint_dir,\n",
    "    filename=f\"moe_distiller_layer_{layer_idx}_{n_routed_experts}a{n_active_experts}\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    min_delta=0.001,       # Minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience=2,          # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=True,        # Print a message when training is stopped\n",
    "    mode='min'            # Training will stop when the quantity monitored has stopped decreasing\n",
    ")\n",
    "\n",
    "print(\"Logger and checkpoint callback setup.\")\n",
    "\n",
    "print(dev)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=params.n_epochs,\n",
    "    accelerator=\"cuda\",\n",
    "    devices=[0],\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    precision=\"bf16-mixed\",\n",
    "    gradient_clip_val=1.0,\n",
    "    accumulate_grad_batches=params.gradient_accumulation_steps,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=1,\n",
    "    # strategy=\"ddp\"  # Add strategy for multi-gpu training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fa9bf-8f97-494d-9353-feb146e4c8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc72f3f-844d-4fa8-bbf3-a221ebb3eb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
