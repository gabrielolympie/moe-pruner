{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea040984-dd1a-434e-a9cf-c71034a2ca6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981701e-18d5-43a1-81ba-8ed6b18a84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_utils import load_intermediate_state\n",
    "from configs import PathConfig\n",
    "\n",
    "path_config=PathConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234e293-7e10-4b11-bc05-829e7372578d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer_idx in range(61):\n",
    "    x = load_intermediate_state(path_config, layer_idx , 0, batch_size=8)\n",
    "    print(layer_idx, float(torch.max(x)), float(torch.mean(x)), float(torch.min(x)), torch.isnan(x).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274e276-1af0-4add-99e6-2ea124b956fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from liger_kernel.transformers import apply_liger_kernel_to_llama\n",
    "from configs import GenerationParams, PathConfig, DistillationParams\n",
    "from torch_utils import save_intermediate_state, save_midlayer_state, load_intermediate_state, load_midlayer_state, destruct_module_optimized, memory_cleanup\n",
    "from modeling_deepseek import DeepseekV3DecoderLayer, DeepseekV3MoE, DeepseekV3ForCausalLM\n",
    "import torch\n",
    "import json\n",
    "from accelerate import init_empty_weights\n",
    "import functools\n",
    "from safetensors import safe_open\n",
    "\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from threading import Semaphore\n",
    "from model_utils import rsetattr, rgetattr, load_model_config, load_weight, map_device, assign_device, get_dataset, get_device_map \n",
    "from Distiller import MOEDistillerLightningModule, prepare_distilled_moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800ee4d-5710-4356-b362-21a77a246cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 3\n",
    "n_routed_experts = 4\n",
    "n_active_experts = 1\n",
    "learning_rate = 8e-4\n",
    "end_factor = 0.1\n",
    "lora_rank = 16\n",
    "lora_alpha = 16\n",
    "device = \"cuda:0\"\n",
    "weights_location='deepseek_v3/'\n",
    "\n",
    "params = DistillationParams(\n",
    "    n_epochs=1,\n",
    "    n_batch=128,\n",
    "    n_train_batch=116,\n",
    "    batch_size=16,\n",
    "    max_length=512,\n",
    "    gradient_accumulation_steps=1,\n",
    "    calibration_batches=16,\n",
    "    learning_rate=learning_rate,\n",
    "    end_factor=end_factor,\n",
    "    temperature=1.0,\n",
    "    lora_type=\"dora\",\n",
    "    lora_rank=lora_rank,\n",
    "    lora_alpha=lora_alpha,\n",
    "    max_workers=8,\n",
    "    fp8_format=\"e4m3\",\n",
    "    distiller_device=device,\n",
    ")\n",
    "\n",
    "# Load Model Config and Tokenizer\n",
    "weight_map, config = load_model_config(weights_location)\n",
    "path_config=PathConfig()\n",
    "# Create empty model\n",
    "with init_empty_weights():\n",
    "    model = DeepseekV3ForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870e0c6-eee6-48f6-981b-f7fa435a9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map = get_device_map(layer_idx, weight_map, device)\n",
    "model.model.layers[layer_idx] = model.model.layers[layer_idx].to_empty(device=device)\n",
    "\n",
    "for i, weight_name in enumerate(tqdm(device_map)):\n",
    "    rsetattr(model, weight_name, load_weight(weights_location, weight_name, weight_map, device))\n",
    "    if i%100 ==0:\n",
    "        memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444acf01-72e6-4bb6-b5a8-834afefd333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_config.expert_activation_dir}/layer_{layer_idx}.pickle\", \"rb\") as f:\n",
    "    act = pickle.load(f)\n",
    "\n",
    "v,c = np.unique(act, return_counts=True)\n",
    "selected_experts = np.flip(np.argsort(c))\n",
    "\n",
    "                  \n",
    "path_config = PathConfig()\n",
    "\n",
    "pl_model = MOEDistillerLightningModule(\n",
    "    weight_map,\n",
    "    path_config,\n",
    "    params,\n",
    "    layer_idx=layer_idx,\n",
    "    n_routed_experts=n_routed_experts,\n",
    "    n_active_experts=n_active_experts,\n",
    "    weights_location=weights_location\n",
    ")\n",
    "\n",
    "pl_model.distillat=prepare_distilled_moe(\n",
    "    model.model.layers[layer_idx].mlp,\n",
    "    selected_experts,\n",
    "    n_routed_experts,\n",
    "    n_active_experts,\n",
    "    params,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "destruct_module_optimized(model)\n",
    "memory_cleanup()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f0a54-7c56-4df2-8e8f-a58a27150dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "input_data = load_midlayer_state(path_config, layer_idx, batch_idx, batch_size=params.batch_size)\n",
    "output_data = load_intermediate_state(path_config, layer_idx, batch_idx, batch_size=params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d5957-c68c-4859-a6ea-cb494927c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model.merge_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10f7d2-48a6-41d6-950c-d107bcc06ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a4a92-8995-4df3-84ec-a1357512e7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
