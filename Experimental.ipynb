{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ed825-b877-40df-8a4d-46a64c67f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from configs import PathConfig\n",
    "from memory_utils import create_empty_layer_fp8, load_model_config\n",
    "from torch_utils import load_intermediate_state, load_midlayer_state, memory_cleanup\n",
    "from configs import PathConfig\n",
    "\n",
    "path_config=PathConfig()\n",
    "layer_idx=8\n",
    "model_name=\"deepseek_v3/\"\n",
    "device_local=\"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50ab77-f994-4611-a630-a082f8ad7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_map, model_config = load_model_config(model_name)\n",
    "layer = create_empty_layer_fp8(model_config, layer_idx=layer_idx, device=device_local)\n",
    "memory_cleanup()\n",
    "layer.load_state_dict(torch.load(f'layers/layer_{layer_idx}.pt', map_location=device_local), assign=True)\n",
    "memory_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f4434-73b3-4da5-961e-cb0fe71afce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_states = load_intermediate_state(path_config, layer_idx-1 , 0).to(device_local)\n",
    "\n",
    "position_ids = torch.arange(\n",
    "    0, 512, dtype=torch.long, device=device_local\n",
    ").unsqueeze(0)\n",
    "\n",
    "residual = hidden_states\n",
    "hidden_states = layer.input_layernorm(hidden_states)\n",
    "\n",
    "hidden_states, _, _ = layer.self_attn(\n",
    "    hidden_states=hidden_states,\n",
    "    attention_mask=None,\n",
    "    position_ids=position_ids,\n",
    "    past_key_value=None,\n",
    "    output_attentions=False,\n",
    "    use_cache=False,\n",
    ")\n",
    "\n",
    "hidden_states = residual + hidden_states\n",
    "residual = hidden_states\n",
    "hidden_states = layer.post_attention_layernorm(hidden_states)\n",
    "\n",
    "# save_midlayer_state(path_config, layer_idx, batch_idx, hidden_states)\n",
    "\n",
    "# hidden_states = layer.mlp(hidden_states)\n",
    "# hidden_states = residual + hidden_states\n",
    "\n",
    "self=layer.mlp\n",
    "\n",
    "base_device=hidden_states.device\n",
    "\n",
    "# identity = hidden_states\n",
    "# orig_shape = hidden_states.shape\n",
    "\n",
    "# hidden_states.to(self.gate.weight.device)\n",
    "# topk_idx, topk_weight, aux_loss = self.gate(hidden_states)\n",
    "# hidden_states.to(base_device)\n",
    "\n",
    "# hidden_states = hidden_states.view(-1, hidden_states.shape[-1])\n",
    "# flat_topk_idx = topk_idx.view(-1)\n",
    "\n",
    "# hidden_states = hidden_states.repeat_interleave(\n",
    "#     self.num_experts_per_tok, dim=0\n",
    "# )\n",
    "\n",
    "# y = torch.empty_like(hidden_states, dtype=hidden_states.dtype, device=hidden_states.device)\n",
    "# y = torch.zeros_like(hidden_states, dtype=hidden_states.dtype, device=hidden_states.device)\n",
    "\n",
    "# for i, expert in enumerate(self.experts):\n",
    "#     expert_device = expert.gate_proj.weight.device\n",
    "#     x = expert(hidden_states[flat_topk_idx == i])\n",
    "    # print(i, torch.max(x))\n",
    "    # y[flat_topk_idx == i] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5e6e9-66cc-4e51-882f-5ca0f8fff8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = exp.gate_proj(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c749f8d-de80-40b4-8898-209bb0a4074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e20bb4-aa01-4420-998a-1bb16f7fa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.gate_proj._weight_unquantized().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a5ab0-b007-4c03-b6eb-8f347b9874d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.to(torch.float16).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aaea00-d55a-4501-9d19-74422d51872a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23575fbd-f208-4a91-99ef-685db48dc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=layer.mlp.experts[240]\n",
    "y=exp(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a2236-451d-419a-8553-1746e18ef54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(y, dim = -1).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27676b8b-648c-42a6-938e-399759d84d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = exp.gate_proj(hidden_states)\n",
    "b = exp.up_proj(hidden_states)\n",
    "\n",
    "c = exp.act_fn(a*b)\n",
    "d=exp.down_proj(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f31e6-5b1e-4794-b2b0-5f5be94a7c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb46eac-615b-4e02-9973-6e94867cc916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c6d53-9e9c-432c-a8c1-183b39044fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(exp.gate_proj._weight_unquantized())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507b988-9f46-4b62-8fd2-ee5ccf365b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e652a-928b-471c-8832-f7ae8e94430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.mlp.experts[250].(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0bdd0-6338-4803-95a8-8a46902f96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c46678-5006-4ec0-b87a-e2b62b2c8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24719ee0-7676-455a-a5cd-16da471931fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "# y = (y.view(*topk_weight.shape, -1) * topk_weight.unsqueeze(-1)).sum(dim=1)\n",
    "# y = y.to(hidden_states.dtype).view(*orig_shape)\n",
    "# y = AddAuxiliaryLoss.apply(y, aux_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8521f0-b114-449f-a571-7d7e62fcc138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414b3d8-b06c-4123-a22b-e5b61c29b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = self.moe_infer(hidden_states, topk_idx, topk_weight).view(*orig_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2840564-7f88-4b7d-af17-1d2229e4f1b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4253d-be1b-4d20-8369-a16d40d1e2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631e0a8-c204-4ccb-9c02-e74f42d83cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6673320-19ee-42f9-b9af-17e094dd2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = layer.forward(\n",
    "    hidden_states=x.to(device_local), position_ids=position_ids\n",
    ")[0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01966a1d-d468-480e-a2b3-efabc38c20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to(dtype=torch.float16, device=\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f407a5-bbef-459c-881e-8ef84b1636b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.max(y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7295c-5c68-4871-94d3-852a90917aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4517e1-7cd2-4fd2-8ba6-85ff09e5c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = []\n",
    "m = []\n",
    "i=0\n",
    "for i in range(256):\n",
    "    l = layer.mlp.experts[i].gate_proj._weight_unquantized()\n",
    "    M.append(torch.max(l))\n",
    "    m.append(torch.min(l))\n",
    "    l = layer.mlp.experts[i].up_proj._weight_unquantized()\n",
    "    M.append(torch.max(l))\n",
    "    m.append(torch.min(l))\n",
    "    l = layer.mlp.experts[i].down_proj._weight_unquantized()\n",
    "    M.append(torch.max(l))\n",
    "    m.append(torch.min(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234e293-7e10-4b11-bc05-829e7372578d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer_idx in range(61):\n",
    "    x = load_intermediate_state(path_config, layer_idx , 0)\n",
    "    print(layer_idx, float(torch.max(x)), float(torch.mean(x)), float(torch.min(x)), torch.isnan(x).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cc724-8b9f-497f-ac04-e06d762c4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.finfo(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bdbc1-3e50-4d2c-b632-4c75d9bbe304",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_intermediate_state(path_config, 13 , 0)\n",
    "x = x.to(dtype=torch.float16, device=\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce261a-b0dd-4056-9b68-57a3bab08189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ea2d9-9308-43d5-a1d8-8796ca5629e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage for weight_dequant\n",
    "M = 512\n",
    "N = 1024\n",
    "block_size = 64  # Example block size\n",
    "\n",
    "x = torch.randint(-128, 127, (M, N), dtype=torch.int8).cuda()  # Simulate quantized weights\n",
    "s = torch.rand((M, triton.cdiv(N, block_size)), dtype=torch.float32).cuda() # Scaling factors for each block\n",
    "\n",
    "y = weight_dequant(x, s, block_size=block_size)\n",
    "\n",
    "print(\"Dequantized weight shape:\", y.shape)\n",
    "print(\"Dequantized weight dtype:\", y.dtype)\n",
    "\n",
    "\n",
    "# Example Usage for fp8_gemm\n",
    "M = 128\n",
    "N = 256\n",
    "K = 64\n",
    "\n",
    "a = torch.randn((M, K), dtype=torch.float16).cuda() # Dummy FP8-like tensors (using FP16 for demonstration)\n",
    "b = torch.randn((N, K), dtype=torch.float16).cuda() # Dummy FP8-like tensors (using FP16 for demonstration)\n",
    "a_s = torch.rand((M,), dtype=torch.float32).cuda() # Scaling factors\n",
    "b_s = torch.rand((N,), dtype=torch.float32).cuda() # Scaling factors\n",
    "\n",
    "c = fp8_gemm(a, a_s, b, b_s)\n",
    "\n",
    "print(\"Result matrix shape:\", c.shape)\n",
    "print(\"Result matrix dtype:\", c.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31843303-99a2-4d91-a9e1-ac58035e21f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fp8_linear import FP8Linear, act_quant\n",
    "import torch\n",
    "\n",
    "layer = FP8Linear(7168, 18432)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
