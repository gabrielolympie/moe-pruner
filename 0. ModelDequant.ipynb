{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d842eade-c8fd-4151-aa7c-90efbc113f3a",
   "metadata": {},
   "source": [
    "## Ressources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5d3fe-04de-4a14-839b-07213c295466",
   "metadata": {},
   "source": [
    "The pipeline was optimized for the following config:\n",
    "- Storage : 2To SSD @512Mo/s\n",
    "- RAM : 128go DDR4 @3600\n",
    "- CPU : Ryzen 9 3950X 16@32 cores\n",
    "- GPU : 2x RTX 3090, aggregated 48gb DDR6X Vram\n",
    "\n",
    "Hence i can  not guarantee that it will work properly on more frugal hardware.\n",
    "Plus the GPU are not NVLink unified, so some optimisation involve manual allocation to one or the other GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9e98c-9fc8-41d9-9f37-3a7a8170dbdf",
   "metadata": {},
   "source": [
    "## Compute the number of parameters for different pruning size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bba445-5354-47ec-9c30-32ef1d8627a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_num_parameters(\n",
    "    n_routed_experts,\n",
    "    num_experts_per_tok,\n",
    "):\n",
    "    num_hidden_layers=61\n",
    "    first_k_dense_replace = 3\n",
    "    num_moe_layer = num_hidden_layers - first_k_dense_replace\n",
    "    \n",
    "    hidden_size=7168\n",
    "    intermediate_size=18432\n",
    "    moe_intermediate_size=2048\n",
    "    \n",
    "    \n",
    "    num_heads  = 128\n",
    "    q_lora_rank = 1536\n",
    "    qk_nope_head_dim = 128\n",
    "    qk_rope_head_dim = 64\n",
    "    kv_lora_rank = 512\n",
    "    v_head_dim=128\n",
    "    \n",
    "    n_shared_experts=1\n",
    "    \n",
    "    vocab_size = 129280\n",
    "    \n",
    "    gate_size = n_routed_experts * hidden_size\n",
    "    \n",
    "    mlp_weights = 3 * hidden_size * intermediate_size\n",
    "    moe_mlp_weights = 3 * hidden_size * moe_intermediate_size\n",
    "    \n",
    "    moe_total_weight = n_routed_experts * moe_mlp_weights\n",
    "    moe_active_weight = num_experts_per_tok * moe_mlp_weights\n",
    "    \n",
    "    q_head_dim = qk_nope_head_dim + qk_rope_head_dim\n",
    "    q_a_proj = hidden_size * q_lora_rank + q_lora_rank * q_head_dim\n",
    "    kv_a_proj_with_mqa = hidden_size * (kv_lora_rank  + qk_rope_head_dim) + kv_lora_rank * (num_heads * (q_head_dim - qk_rope_head_dim  + v_head_dim))\n",
    "    o_proj_weight = num_heads * v_head_dim * hidden_size\n",
    "    attention_weight = q_a_proj + 2 * kv_a_proj_with_mqa + o_proj_weight\n",
    "    \n",
    "    base_weight_per_moe_layer = attention_weight + n_shared_experts * moe_mlp_weights + gate_size\n",
    "    base_weight_per_mlp_layer = attention_weight + mlp_weights\n",
    "    \n",
    "    base_model_weight = base_weight_per_moe_layer * num_moe_layer + base_weight_per_mlp_layer * first_k_dense_replace + 2 * vocab_size * hidden_size\n",
    "    \n",
    "    total_expert_weight = moe_total_weight * num_moe_layer\n",
    "    active_expert_weight = moe_active_weight * num_moe_layer\n",
    "    \n",
    "    active_model_weight = active_expert_weight + num_moe_layer + base_model_weight\n",
    "    total_model_weight = total_expert_weight + num_moe_layer + base_model_weight\n",
    "    \n",
    "    print(f\"{n_routed_experts} @ {num_experts_per_tok} => {int(round(total_model_weight/1e9,0))}B @ {int(round(active_model_weight/1e9,0))}B parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796530c-8061-4803-a7a2-077cac75ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_routed_experts=256\n",
    "num_experts_per_tok=8\n",
    "calc_num_parameters(n_routed_experts, num_experts_per_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54c46a-bbdb-4048-b616-d17e8c86b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [\n",
    "    (256,8),\n",
    "    (22,8),\n",
    "    (16,8),\n",
    "    (8,8),\n",
    "]\n",
    "\n",
    "for elt in p:\n",
    "    calc_num_parameters(*elt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69d425-c1fb-4289-b6e9-556e43edaae0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abf472-db10-4106-9224-1ead46911ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from accelerate import init_empty_weights\n",
    "from accelerate.utils import load_offloaded_weight\n",
    "import json\n",
    "from accelerate import load_checkpoint_in_model, dispatch_model\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import gc\n",
    "import _pickle as pickle\n",
    "import os\n",
    "# from Distiller import MOEDistiller, count_parameters\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, AutoConfig\n",
    "\n",
    "import torch\n",
    "\n",
    "from memory_utils import load_module_weights_and_freeze_optimized, load_weight_cached, destruct_module_optimized\n",
    "from Distiller import load_model_config,create_empty_model,create_empty_layer, create_empty_layer_fp8\n",
    "\n",
    "from liger_kernel.transformers import apply_liger_kernel_to_llama\n",
    "\n",
    "from copy import deepcopy\n",
    "from Distiller import MOEDistillerV3\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import os\n",
    "from modeling_deepseek import _prepare_4d_causal_attention_mask\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "base_path = '/home/golympie/data/'\n",
    "\n",
    "# # ## Load\n",
    "weight_map, config = load_model_config(\"deepseek_v3\")\n",
    "weight_file = weight_map['model.embed_tokens.weight']\n",
    "\n",
    "\n",
    "apply_liger_kernel_to_llama()\n",
    "\n",
    "model_name = \"DeepSeek-V3\"\n",
    "offload_folder = model_name+'_offload/'\n",
    "output_directory = model_name+'_runner_output/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-V3\", trust_remote_code=True)\n",
    "\n",
    "def memory_cleanup():\n",
    "    \"\"\"Perform thorough memory cleanup\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235aba0-5544-40b3-bf01-ec0376be3f35",
   "metadata": {},
   "source": [
    "## Save layers to disk for easier loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80caaa6a-f8f8-447f-9c11-cc67d33ef680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"layers\", exist_ok=True)\n",
    "# model = create_empty_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7e256-e7b8-465a-a877-401bf43e4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Embed\n",
    "# model.model.embed_tokens = load_module_weights_and_freeze_optimized(\n",
    "#     model.model.embed_tokens,\n",
    "#     f\"model.embed_tokens\",\n",
    "#     weight_map,\n",
    "#     \"deepseek_v3\",\n",
    "#     max_workers=32,\n",
    "#     fp8_format=\"e4m3\",\n",
    "# )\n",
    "\n",
    "# torch.save(model.model.embed_tokens.state_dict(), 'layers/embed_tokens.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07c96c-42ed-4dcb-9fa9-d0cc58a56d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## End norm\n",
    "# model.model.norm = load_module_weights_and_freeze_optimized(\n",
    "#     model.model.norm,\n",
    "#     f\"model.norm\",\n",
    "#     weight_map,\n",
    "#     \"deepseek_v3\",\n",
    "#     max_workers=32,\n",
    "#     fp8_format=\"e4m3\",\n",
    "# )\n",
    "\n",
    "# torch.save(model.model.norm.state_dict(), 'layers/norm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b78c02-1454-4889-b6f2-8c99c6f1a4ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Lm head\n",
    "# model.lm_head = load_module_weights_and_freeze_optimized(\n",
    "#     model.lm_head,\n",
    "#     f\"lm_head\",\n",
    "#     weight_map,\n",
    "#     \"deepseek_v3\",\n",
    "#     max_workers=32,\n",
    "#     fp8_format=\"e4m3\",\n",
    "# )\n",
    "\n",
    "# torch.save(model.lm_head.state_dict(), 'layers/lm_head.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ccd67-2099-4ddc-9a6a-e41eea2d4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layers\n",
    "for i in tqdm(range(62)):\n",
    "    \n",
    "    layer = create_empty_layer(config, layer_idx=i)\n",
    "    layer = load_module_weights_and_freeze_optimized(\n",
    "        layer,\n",
    "        f\"model.layers.{i}\",\n",
    "        weight_map,\n",
    "        \"deepseek_v3\",\n",
    "        max_workers=16,\n",
    "        fp8_format=\"e4m3\",\n",
    "    )\n",
    "    memory_cleanup()\n",
    "\n",
    "    torch.save(layer.state_dict(), f'./layers/layer_{i}.pt')\n",
    "    destruct_module_optimized(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852b613-de11-4540-b18c-760f85a94aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
